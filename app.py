### OVERALL CODE
#–ª–∏–±—ã
#–±–∞–∑–∞
#!pip install streamlit
#!pip install ydata-profiling

import os
import numpy as np
import pandas as pd
import streamlit as st
from sklearn.model_selection import train_test_split
#from ydata_profiling import ProfileReport
import inspect
from collections import Counter
import seaborn as sns
import matplotlib.pyplot as plt
#classification models
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from imblearn.over_sampling import SMOTE, RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import VotingClassifier, StackingClassifier
from collections import Counter
from sklearn.preprocessing import LabelEncoder, StandardScaler
import keras
from tensorflow.keras.optimizers import Adam
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical
st.set_page_config(page_title="HSE | –¢–ò–ò–ü–ê", layout="wide")

st.title("¬© HSE | –¢–ò–ò–ü–ê")
st.markdown("**Fast-touch classification-analytical tool**")

st.markdown("---")

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º–∞–Ω–¥–µ
with st.expander("‚Ñπ–û –∫–æ–º–∞–Ω–¥–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤"):
    st.markdown("""
    **–ö–æ–º–∞–Ω–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞:**
    - –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ò–ª—å—è—â–µ–Ω–∫–æ ‚Äî Team Leader
    - –í–∞–¥–∏–º –ö–∞–∑–∞–∫–æ–≤ ‚Äî Master of Machine Learning
    - –ê–Ω–¥—Ä–µ–π –®–∏—Ä—à–æ–≤ ‚Äî Business Developer
    - –¢–∞—Ç—å—è–Ω–∞ –ß–µ—Ä–Ω—ã—Ö ‚Äî Designer
    """)

# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
with st.expander("–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Å–µ—Ä–≤–∏—Å–∞", expanded=True):
    st.markdown("""
    1. *–í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω—É—é —Ç–µ–º—É* –∞–Ω–∞–ª–∏–∑–∞
    2. *–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ* —Å –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    3. *–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ* –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    4. *–ó–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑* ‚Äî –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –¥–æ–≤–µ—Ä—å—Ç–µ—Å—å –Ω–∞–º. *–î–∞–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º—É –≤—Ä–µ–º—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.*
    5. *–ò–∑—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã* ‚Äî –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.
    6. *–í—ã–±–µ—Ä–∏—Ç–µ* –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏ *–ø—Ä–∏–º–µ–Ω–∏—Ç–µ* –µ—ë –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    """)

st.markdown("---")

#st.title("–ó–∞–≥—Ä—É–∑–∏ —Ñ–∞–π–ª —Å—é–¥–∞, –¥—Ä—É–≥")
#uploaded_file = st.file_uploader("Select a CSV file", type=["csv"])
st.title("–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª (CSV –∏–ª–∏ Excel)", type=["csv", "xls", "xlsx"])

if uploaded_file is not None:
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
    file_name = uploaded_file.name.lower()

    if file_name.endswith('.csv'):
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è CSV —Ñ–∞–π–ª–æ–≤
        sep_sign = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å",
            (";", ",", " ", "|"), index=0)

        decimal_sign = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç–¥–µ–ª–∏—Ç–µ–ª—å –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏",
            (".", ","), index=1)

        df = pd.read_csv(uploaded_file, sep=sep_sign, decimal=decimal_sign)

    elif file_name.endswith(('.xls', '.xlsx')):
        df = pd.read_excel(uploaded_file)

    st.write("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö:")
    st.dataframe(df.head())
    backup_df = df.copy()
 
#if uploaded_file is not None:
  #seps = [";", ","]
  #decimals = [".", ","]
  #sep_sign = ";"
  #sep_sign = st.selectbox(
   # "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å",
   # (";", ",", " ", "/"))
  #decimal_sign = ","
  #decimal_sign = st.selectbox(
    #"–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç–¥–µ–ª–∏—Ç–µ–ª—å –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏",
    #(".", ","))
  #df = pd.read_csv(uploaded_file, sep = sep_sign, decimal = decimal_sign)
  #st.write("–¢–≤–æ–π –¥–∞—Ç–∞—Å–µ—Ç:")
  #st.dataframe(df.head())
  #backup_df = df.copy()


#—á—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
#def read_data(df):
  #return df
#def handle_missing_values(df, option):

    #df_processed = df.copy()
    
    #if option == "–î—Ä–æ–ø–Ω—É—Ç—å":
        #df_processed = df_processed.dropna()
    #elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å":
        #for col in df_processed.columns:
            #if pd.api.types.is_numeric_dtype(df_processed[col]):
                #df_processed[col] = df_processed[col].fillna(0)
            #else:
                #df_processed[col] = df_processed[col].fillna("0")
    #elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–µ–¥–∏–∞–Ω—É":
        #for col in df_processed.columns:
            #if pd.api.types.is_numeric_dtype(df_processed[col]):
                #median_val = df_processed[col].median()
                #df_processed[col] = df_processed[col].fillna(median_val)
            #else:
                #df_processed[col] = df_processed[col].fillna("0")
    
    #return df_processed
# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ Streamlit
def handle_missing_values(df, option, categorical_method="mode"):
    df_processed = df.copy()

    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
    for col in df_processed.columns:
        # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if pd.api.types.is_numeric_dtype(df_processed[col]):
            if option == "–£–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏":
                df_processed = df_processed.dropna(subset=[col])
            elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å":
                df_processed[col] = df_processed[col].fillna(0)
            elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–µ–¥–∏–∞–Ω—É":
                df_processed[col] = df_processed[col].fillna(df_processed[col].median())
            elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ":
                df_processed[col] = df_processed[col].fillna(df_processed[col].mean())
            elif option == "–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è":
                df_processed[col] = df_processed[col].interpolate()

        # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        else:
            if option == "–£–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏":
                df_processed = df_processed.dropna(subset=[col])
            elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–æ–¥—É":
                df_processed[col] = df_processed[col].fillna(df_processed[col].mode()[0])
            elif option == "–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é 'Unknown'":
                df_processed[col] = df_processed[col].fillna("Unknown")
            elif option == "–≠–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è (–ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)":
                df_processed[col] = df_processed[col].fillna(method='fill')

    return df_processed
st.title("–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ")

# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é df
if 'df' not in globals():
    st.warning("–î–∞—Ç–∞—Ñ—Ä–µ–π–º –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–∞–º—è—Ç–∏. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
    st.stop()
# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–ø—É—Å–∫–∞—Ö
st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
missing_stats = df.isna().sum()
missing_percent = (missing_stats / len(df)) * 100
missing_df = pd.DataFrame({
    "–ö–æ–ª–æ–Ω–∫–∞": missing_stats.index,
    "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤": missing_stats.values,
    "–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤": missing_percent.values.round(2)
})
st.dataframe(missing_df)

# –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
st.markdown("---")
st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤")

col1, col2 = st.columns(2)
with col1:
    method = st.selectbox(
        "–ú–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤:",
        options=[
            "–£–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏",
            "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å",
            "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–µ–¥–∏–∞–Ω—É",
            "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ",
            "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–æ–¥—É",
            "–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é 'Unknown'",
            "–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è",
            "–≠–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è (–ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)"
        ],
        index=2,
        help="–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"
    )

with col2:
    show_details = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—è—Å–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤", value=True)

if show_details:
    with st.expander("üìö –ü–æ—è—Å–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏"):
        st.markdown("""
        - **–£–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏** - –ø–æ–ª–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö –ø—Ä–æ–ø—É—Å–∫–∏
        - **–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å** - –∑–∞–º–µ–Ω–∞ –≤—Å–µ—Ö –ø—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–∞ 0 (–¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
        - **–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–µ–¥–∏–∞–Ω—É** - –∑–∞–º–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –º–µ–¥–∏–∞–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (—É—Å—Ç–æ–π—á–∏–≤–æ –∫ –≤—ã–±—Ä–æ—Å–∞–º)
        - **–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ** - –∑–∞–º–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ —Å—Ä–µ–¥–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (–º–æ–∂–µ—Ç –∏—Å–∫–∞–∂–∞—Ç—å—Å—è –≤—ã–±—Ä–æ—Å–∞–º–∏)
        - **–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–æ–¥—É** - –∑–∞–º–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (–¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
        - **–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é 'Unknown'** - –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–ø—É—Å–∫–µ
        - **–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è** - –ª–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π (–¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)
        - **–≠–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è** - –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏–º –∏–∑–≤–µ—Å—Ç–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (–º–µ—Ç–æ–¥ 'forward fill')
        """)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
if st.checkbox("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"): #, type="primary"):
    with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
        df = handle_missing_values(df, method)
        st.success("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.markdown("---")
        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        col1, col2 = st.columns(2)
        with col1:
            st.metric("–ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫", len(backup_df))
        with col2:
            st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏", len(df))

        st.dataframe(df.head(10))
# –í—ã–ø–∞–¥–∞—é—â–∏–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–µ—Ç–æ–¥–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤
#missing_values_option = st.selectbox(
    #"–ß—Ç–æ –¥–µ–ª–∞—Ç—å —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏?",
    #options=["–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å", "–î—Ä–æ–ø–Ω—É—Ç—å", "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–µ–¥–∏–∞–Ω—É"],
    #index=0  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–±—Ä–∞–Ω "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å"
#)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞
#df = handle_missing_values(df, missing_values_option)

# –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
#st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏")
#st.write(f"–í—ã–±—Ä–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥: {missing_values_option}")
#st.write(f"–ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(backup_df)}")
#st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(df)}")
#df = st.session_state.df
# –ü–æ–∫–∞–∑–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
st.dataframe(df)

#–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ —Ä–∞–±–æ—Ç–æ–π
st.title("–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")

st.write(df.describe())

# –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
st.title("–í–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
st.markdown("---")

with st.expander("–û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö", expanded=True):
    st.subheader("–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

    # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ describe()
    desc = df.describe().T
    desc['missing'] = df.isna().sum()
    desc['missing_percent'] = (desc['missing'] / len(df)).round(2)
    desc['dtype'] = df.dtypes
    desc['unique'] = df.nunique()

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—ã–≤–æ–¥
    st.dataframe(
        desc.style.format({
            'mean': '{:.2f}',
            'std': '{:.2f}',
            'min': '{:.2f}',
            '25%': '{:.2f}',
            '50%': '{:.2f}',
            '75%': '{:.2f}',
            'max': '{:.2f}',
            'missing_percent': '{:.0%}'
        }),
        use_container_width=True
    )

st.markdown("---")
st.header("–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è")

# –í—ã–±–æ—Ä —Ç–∏–ø–∞ –≥—Ä–∞—Ñ–∏–∫–∞
chart_type = st.radio(
    "–¢–∏–ø –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:",
    ["–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞", "–Ø—â–∏–∫ —Å —É—Å–∞–º–∏ (Boxplot)", "–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"],
    horizontal=True
)

col1, col2 = st.columns([3, 1])
with col1:
    selected_col = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
        options=df.select_dtypes(include=['number']).columns,
        index=0
    )

with col2:
    if chart_type == "–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞":
        bins = st.slider(
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤:",
            min_value=5,
            max_value=50,
            value=int(np.sqrt(len(df)) if len(df) > 0 else 20)
        )

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞
plt.style.use('dark_background')
fig, ax = plt.subplots(figsize=(10, 5))

if chart_type == "–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞":
    sns.histplot(df[selected_col], bins=bins, kde=True, ax=ax)
    ax.set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {selected_col}')
    ax.set_xlabel(selected_col)
    ax.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
elif chart_type == "–Ø—â–∏–∫ —Å —É—Å–∞–º–∏ (Boxplot)":
    sns.boxplot(x=df[selected_col], ax=ax)
    ax.set_title(f'Boxplot –¥–ª—è {selected_col}')
elif chart_type == "–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è":
    sns.kdeplot(df[selected_col], ax=ax, fill=True)
    ax.set_title(f'–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è {selected_col}')
    ax.set_xlabel(selected_col)
    ax.set_ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å')

st.pyplot(fig)

st.markdown("---")
    # 1. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏
#st.subheader("–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞")
#selected_col = st.selectbox(
#        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã",
#        options=df.columns,
#        index=2
#    )
#hist_values = np.histogram(df[selected_col], bins=int(round( len(df[selected_col])**0.5 ,0)))
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame –¥–ª—è st.bar_chart
#hist_df = pd.DataFrame({
        #'bin_left': hist_values[1][:-1],
        #'bin_right': hist_values[1][1:],
        #'count': hist_values[0]
    #})
#hist_df['bin'] = hist_df.apply(lambda x: f"{x['bin_left']:.2f}-{x['bin_right']:.2f}", axis=1)
    
# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –±–∞—Ä—á–∞—Ä—Ç
#st.bar_chart(hist_df.set_index('bin')['count'])
    
    # 2. Scatter plot —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
st.subheader("Scatter plot")
col1, col2, col3, col4 = st.columns(4)
    
with col1:
  x_axis = st.selectbox(
            "–û—Å—å X",
            options=df.columns,
            index=0
        )
with col2:
  y_axis = st.selectbox(
            "–û—Å—å Y",
            options=df.columns,
            index=1 if len(df.columns) > 1 else 0
        )
    
with col3:
  color_col = st.selectbox(
            "–¶–≤–µ—Ç",
            options=["None"] + list(df.columns),
            index=0
        )
with col4:
  size_col = st.selectbox(
            "–†–∞–∑–º–µ—Ä",
            options=["None"] + list(df.columns),
            index=0
        )    
if (color_col == "None") & (size_col == "None"):
    st.scatter_chart(df, x=x_axis, y=y_axis)
elif (size_col == "None") & (color_col != "None"):
    st.scatter_chart(df, x=x_axis, y=y_axis, color=color_col)
elif (size_col != "None") & (color_col == "None"):
    st.scatter_chart(df, x=x_axis, y=y_axis, size = size_col)
elif (size_col != "None") & (color_col != "None"):
    st.scatter_chart(df, x=x_axis, y=y_axis, color = color_col, size = size_col)

#st.subheader("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è")
#    
#    # 1. –í—ã–±–æ—Ä —Ç–∞—Ä–≥–µ—Ç–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (y)
#target_col = st.selectbox(
#        "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∞—Ä–≥–µ—Ç–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (y)",
#        options=df.columns,
#        index=0,  # –î–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –ø–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞
#        key="target_select"
#    )
    
#    # 2. –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (X) - –∏—Å–∫–ª—é—á–∞–µ–º —Ç–∞—Ä–≥–µ—Ç –∏–∑ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
#available_features = [col for col in df.columns if col != target_col]
    
#selected_features = st.multiselect(
#        "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ (X)",
#        options=available_features,
#        default=available_features,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
#        key="features_select"
#    )
#    
#    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –≤—ã–±—Ä–∞–Ω—ã —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫
#if not selected_features:
#  st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –º–æ–¥–µ–ª–∏")
#      
#if selected_features:    
#    # –§–æ—Ä–º–∏—Ä—É–µ–º X –∏ y
#  y = df[target_col]
#  X = df[selected_features]
#    
#    # 3. –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ train/test
#  X_train, X_test, y_train, y_test = train_test_split(
#        X, y, 
#        test_size=0.2, 
#        random_state=42
#    )
# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—é
st.subheader("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è")
st.markdown("---")

# 1. –í—ã–±–æ—Ä —Ç–∞—Ä–≥–µ—Ç–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (y)
target_col = st.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∞—Ä–≥–µ—Ç–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (y)",
    options=df.columns,
    index=0,
    key="target_select"
)

# 2. –í—ã–±–æ—Ä ID –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (–¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π)
id_cols = st.multiselect(
    "–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ-–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (–Ω–µ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ –º–æ–¥–µ–ª–∏)",
    options=[col for col in df.columns if col != target_col],
    key="id_cols"
)

# 3. –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (X)
available_features = [col for col in df.columns if col != target_col and col not in id_cols]

selected_features = st.multiselect(
    "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ (X)",
    options=available_features,
    default=available_features,
    key="features_select"
)

if not selected_features:
    st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –º–æ–¥–µ–ª–∏")
    st.stop()

# 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
with st.expander("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö", expanded=True):
    st.subheader("–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
    numeric_cols = [col for col in selected_features if pd.api.types.is_numeric_dtype(df[col])]
    norm_cols = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (StandardScaler)",
        options=numeric_cols,
        help="–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é (z-score)"
    )

    st.subheader("–õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ")
    log_cols = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è",
        options=numeric_cols,
        help="–ü—Ä–∏–º–µ–Ω—è–µ—Ç log(x+1) –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–∞–≤–æ—Å—Ç–æ—Ä–æ–Ω–Ω–µ-—Å–∫–æ—à–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
    )

    st.subheader("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    categorical_cols = [col for col in selected_features if not pd.api.types.is_numeric_dtype(df[col])]
    dummy_cols = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è one-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è",
        options=categorical_cols,
        help="–°–æ–∑–¥–∞—Å—Ç dummy-–ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (n-1) –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
    )

    st.subheader("–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤")
    if pd.api.types.is_numeric_dtype(df[target_col]):
        st.warning("–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ —Ç–∞—Ä–≥–µ—Ç–∞")
    else:
        balance_method = st.selectbox(
            "–ú–µ—Ç–æ–¥ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤",
            options=["–ù–µ—Ç", "Random Oversampling", "SMOTE", "Random Undersampling"],
            index=0,
            help="–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤ –≤ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ"
        )

# 5. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞–∑–±–∏–µ–Ω–∏—è
test_size = st.slider(
    "–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ (%)",
    min_value=5,
    max_value=40,
    value=20,
    step=5
)

random_state = st.number_input(
    "Random state –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏",
    min_value=0,
    value=42
)
    
    # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–±–∏–µ–Ω–∏–∏
#  st.success("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã!")
#  st.write(f"–í—ã–±—Ä–∞–Ω —Ç–∞—Ä–≥–µ—Ç: {target_col}")
#  st.write(f"–í—ã–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)}")
#  st.write(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X_train.shape[0]}")
#  st.write(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_test.shape[0]}")
def preprocess_data(data, target_col, id_cols, features, norm_cols, log_cols, dummy_cols,
                   balance_method, test_size, random_state):

    # –í—ã–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ç–∞—Ä–≥–µ—Ç
    X = data[features]
    y = data[target_col]
    ids = data[id_cols] if id_cols else None

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size/100,
        random_state=random_state,
        stratify=y if not pd.api.types.is_numeric_dtype(y) else None
    )

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º ID –¥–ª—è train –∏ test
    if ids is not None:
        train_ids = ids.loc[X_train.index]
        test_ids = ids.loc[X_test.index]
    else:
        train_ids, test_ids = None, None

    # 1. –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ
    for col in log_cols:
        X_train[col] = np.log1p(X_train[col])
        X_test[col] = np.log1p(X_test[col])

    # 2. One-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
    if dummy_cols:
        encoder = OneHotEncoder(drop='first', sparse=False)
        train_encoded = encoder.fit_transform(X_train[dummy_cols])
        test_encoded = encoder.transform(X_test[dummy_cols])

        encoded_cols = encoder.get_feature_names_out(dummy_cols)
        train_encoded_df = pd.DataFrame(train_encoded, columns=encoded_cols, index=X_train.index)
        test_encoded_df = pd.DataFrame(test_encoded, columns=encoded_cols, index=X_test.index)

        X_train = X_train.drop(dummy_cols, axis=1).join(train_encoded_df)
        X_test = X_test.drop(dummy_cols, axis=1).join(test_encoded_df)

    # 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    if norm_cols:
        scaler = StandardScaler()
        X_train[norm_cols] = scaler.fit_transform(X_train[norm_cols])
        X_test[norm_cols] = scaler.transform(X_test[norm_cols])

    # 4. –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤
    if balance_method != "–ù–µ—Ç" and not pd.api.types.is_numeric_dtype(y_train):
        if balance_method == "Random Oversampling":
            sampler = RandomOverSampler(random_state=random_state)
        elif balance_method == "SMOTE":
            sampler = SMOTE(random_state=random_state)
        elif balance_method == "Random Undersampling":
            sampler = RandomUnderSampler(random_state=random_state)

        X_train, y_train = sampler.fit_resample(X_train, y_train)

    return X_train, X_test, y_train, y_test, train_ids, test_ids

# –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
if st.checkbox("–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
    with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
        # –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º
        X_train, X_test, y_train, y_test, train_ids, test_ids = preprocess_data(
            data=df,
            target_col=target_col,
            id_cols=id_cols,
            features=selected_features,
            norm_cols=norm_cols,
            log_cols=log_cols,
            dummy_cols=dummy_cols,
            balance_method=balance_method,
            test_size=test_size,
            random_state=random_state
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ session_state
        #st.session_state.update({
            #'X_train': X_train,
            #'X_test': X_test,
            #'y_train': y_train,
            #'y_test': y_test,
            #'train_ids': train_ids,
            #'test_ids': test_ids
        #})

        st.success("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã!")

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.markdown("---")
        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏")
        st.header("–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
        st.subheader(f"–ê–Ω–∞–ª–∏–∑ –ø–æ –∫–ª–∞—Å—Å–∞–º ({target_col})")
        class_stats = df.groupby(target_col,as_index=False).mean().merge(pd.DataFrame(df[target_col].value_counts()).reset_index(), how='left')
        st.dataframe(class_stats)
        col1, col2 = st.columns(2)
        with col1:
            st.metric("–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞", f"{len(X_train)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
            st.metric("–ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏", X_train.shape[1])
            if hasattr(y_train, 'value_counts'):
                st.write("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (train):")
                st.dataframe(y_train.value_counts(normalize=True))

        with col2:
            st.metric("–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞", f"{len(X_test)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
            st.metric("–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–∞", f"{test_size}%")
            if hasattr(y_test, 'value_counts'):
                st.write("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (test):")
                st.dataframe(y_test.value_counts(normalize=True))

        # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
        st.markdown("---")
        st.subheader("–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö")

        tab1, tab2 = st.tabs(["–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞", "–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞"])
        with tab1:
            display_df = X_train.head(5).copy()
            display_df[target_col] = y_train.head(5).values
            if train_ids is not None:
                display_df = pd.concat([train_ids.head(5), display_df], axis=1)
            st.dataframe(display_df)

        with tab2:
            display_df = X_test.head(5).copy()
            display_df[target_col] = y_test.head(5).values
            if test_ids is not None:
                display_df = pd.concat([test_ids.head(5), display_df], axis=1)
            st.dataframe(display_df)

# –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ ML –º–æ–¥–µ–ª—è—Ö
#if 'X_train' in st.session_state:
    #X_train = st.session_state.X_train
    #X_test = st.session_state.X_test
    #y_train = st.session_state.y_train
    #y_test = st.session_state.y_test
if 'X_train' not in globals():
    st.warning("–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–∞–Ω–Ω—ã–µ")
    st.stop()
else:
    X_train = X_train
    X_test = X_test
    y_train = y_train
    y_test = y_test


def plot_confusion_matrix(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred)
    #st.write(cm)
    fig, ax = plt.subplots(figsize=(10, 12))
    sns.heatmap(cm, annot=True, cbar=False, fmt = "d",  ax=ax)
    ax.set_title(title)
    ax.set_xlabel('Predicted')
    ax.set_ylabel('Actual')
    #plt.tight_layout()
    #st.pyplot(fig)
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j+0.5, i+0.5, str(cm[i, j]),
                    ha='center', va='center', color='white')
    
    st.pyplot(fig, clear_figure=True)

def evaluate_model(model, X_train, X_test, y_train, y_test, model_name, use_cv=False, cv_folds=5):
    if use_cv:
        scores = cross_val_score(model, X_train, y_train, cv=cv_folds, scoring='accuracy')
        st.write(f"–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è (Accuracy): –°—Ä–µ–¥–Ω–µ–µ = {scores.mean():.4f}, Std = {scores.std():.4f}")
        model.fit(X_train, y_train)
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)
    else:
        model.fit(X_train, y_train)
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)

    metrics = {
        'Accuracy': [
            accuracy_score(y_train, y_train_pred),
            accuracy_score(y_test, y_test_pred)
        ],
        'Precision': [
            precision_score(y_train, y_train_pred, average='weighted'),
            precision_score(y_test, y_test_pred, average='weighted')
        ],
        'Recall': [
            recall_score(y_train, y_train_pred, average='weighted'),
            recall_score(y_test, y_test_pred, average='weighted')
        ],
        'F1': [
            f1_score(y_train, y_train_pred, average='weighted'),
            f1_score(y_test, y_test_pred, average='weighted')
        ]
    }

    metrics_df = pd.DataFrame(metrics, index=['Train', 'Test'])

    st.subheader(f"–ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫ –¥–ª—è {model_name}")
    col1, col2 = st.columns(2)
    with col1:
        plot_confusion_matrix(y_train, y_train_pred, f'Train\n{model_name}')
    with col2:
        plot_confusion_matrix(y_test, y_test_pred, f'Test\n{model_name}')

    return model, metrics_df, y_train_pred, y_test_pred  
models = {}
#logre–ø
def logistic_regression(X_train, X_test, y_train, y_test, use_cv=False, cv_folds=5):
  logreg = LogisticRegression(
    multi_class='multinomial',
    max_iter = 1000
)
  logreg.fit(X_train, y_train)
  return evaluate_model(logreg, X_train, X_test, y_train, y_test, "Logistic Regression", use_cv=use_cv, cv_folds=cv_folds)

#tree
def tree(X_train, X_test, y_train, y_test, max_depth_target = 10, min_samples_split_target = 10, use_cv=False, cv_folds=5):
  tree = DecisionTreeClassifier(
    max_depth = max_depth_target,             # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞
    min_samples_split = min_samples_split_target,     # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
)
  tree.fit(X_train, y_train)
  return evaluate_model(tree, X_train, X_test, y_train, y_test, "Decision Tree", use_cv=use_cv, cv_folds=cv_folds)

#forest
def random_forest(X_train, X_test, y_train, y_test, estimators_target = 50, max_depth_target = 10, min_samples_split_target = 10, use_cv=False, cv_folds=5):
  random_forest = RandomForestClassifier(
    n_estimators = estimators_target,  # –ß–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤
    max_features='sqrt',
    max_depth = max_depth_target,
    min_samples_split = min_samples_split_target
)
  random_forest.fit(X_train, y_train)
  return evaluate_model(random_forest, X_train, X_test, y_train, y_test, "Random Forest", use_cv=use_cv, cv_folds=cv_folds)


#xgboost
def xgboost(X_train, X_test, y_train, y_test, learning_rate=0.01, n_estimators=50, max_depth=10, use_cv=False, cv_folds=5):
    le = LabelEncoder()
    y_train_encoded = le.fit_transform(y_train)
    y_test_encoded = le.transform(y_test)

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    xgboost_model = XGBClassifier(
        learning_rate=learning_rate,
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=42,
        eval_metric='mlogloss',  # –î–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        use_label_encoder=False  # –ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
    )

    if use_cv:
        scores = cross_val_score(xgboost_model, X_train, y_train_encoded, cv=cv_folds, scoring='accuracy')
        st.write(f"–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è (Accuracy): –°—Ä–µ–¥–Ω–µ–µ = {scores.mean():.4f}, Std = {scores.std():.4f}")

    xgboost_model.fit(X_train, y_train_encoded)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_train_pred = le.inverse_transform(xgboost_model.predict(X_train))
    y_test_pred = le.inverse_transform(xgboost_model.predict(X_test))

    # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
    metrics = {
        'Accuracy': [
            accuracy_score(y_train, y_train_pred),
            accuracy_score(y_test, y_test_pred)
        ],
        'Precision': [
            precision_score(y_train, y_train_pred, average='weighted'),
            precision_score(y_test, y_test_pred, average='weighted')
        ],
        'Recall': [
            recall_score(y_train, y_train_pred, average='weighted'),
            recall_score(y_test, y_test_pred, average='weighted')
        ],
        'F1': [
            f1_score(y_train, y_train_pred, average='weighted'),
            f1_score(y_test, y_test_pred, average='weighted')
        ],
    }

    metrics_df = pd.DataFrame(metrics, index=['Train', 'Test'])

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    st.subheader("–ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫ –¥–ª—è XGBoost")
    col1, col2 = st.columns(2)
    with col1:
        plot_confusion_matrix(y_train, y_train_pred, 'Train\nXGBoost')
    with col2:
        plot_confusion_matrix(y_test, y_test_pred, 'Test\nXGBoost')

    # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    #st.subheader("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    #fig, ax = plt.subplots(figsize=(10, 6))
    #xgb.plot_importance(xgboost_model, ax=ax)
    #st.pyplot(fig)

    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    train_results = pd.DataFrame({
        #'index': X_train.index,
        #'Actual': y_train,
        'Predicted': y_train_pred
    })

    test_results = pd.DataFrame({
        #'index': X_test.index,
        #'Actual': y_test,
        'Predicted': y_test_pred
    })

    return xgboost_model, metrics_df, y_train_pred, y_test_pred

#Support-vector-calc
def svc(X_train, X_test, y_train, y_test, use_cv=False, cv_folds=5):
  svc = SVC()
  svc.fit(X_train, y_train)
  return evaluate_model(svc, X_train, X_test, y_train, y_test, "SVC", use_cv=use_cv, cv_folds=cv_folds)

#knn
def knn_classifier(X_train, X_test, y_train, y_test, neighbors_target = 10, use_cv=False, cv_folds=5):
  knn = KNeighborsClassifier(n_neighbors= neighbors_target)
  knn.fit(X_train, y_train)
  return evaluate_model(knn, X_train, X_test, y_train, y_test, "KNN", use_cv=use_cv, cv_folds=cv_folds)

def perceptron_classifier(X_train, X_test, y_train, y_test,
                        layers_target=2, neurons_target=50,
                        learning_rate_target=0.01, epochs_target=10, use_cv=False, cv_folds=5):
    le = LabelEncoder()
    y_train_encoded = le.fit_transform(y_train)
    y_test_encoded = le.transform(y_test)

    y_train_onehot = to_categorical(y_train_encoded)
    y_test_onehot = to_categorical(y_test_encoded)

    model = Sequential()
    #model = Classifier()
    model.add(Dense(neurons_target, input_dim=X_train.shape[1], activation='relu'))

    for _ in range(layers_target ):
        model.add(Dense(neurons_target, activation='relu'))

    model.add(Dense(y_train_onehot.shape[1], activation='softmax'))

    model.compile(
        loss='categorical_crossentropy',
        optimizer=Adam(learning_rate=learning_rate_target),
        metrics=['accuracy']
    )

    history = model.fit(
        X_train, y_train_onehot,
        epochs=epochs_target,
        batch_size=32,
        validation_data=(X_test, y_test_onehot),
        verbose=0
    )

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_train_pred = model.predict(X_train, verbose=0)
    y_test_pred = model.predict(X_test, verbose=0)

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ–±—Ä–∞—Ç–Ω–æ –≤ –∫–ª–∞—Å—Å—ã
    y_train_pred_classes = le.inverse_transform(np.argmax(y_train_pred, axis=1))
    y_test_pred_classes = le.inverse_transform(np.argmax(y_test_pred, axis=1))

    # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
    metrics = {
        'Accuracy': [
            accuracy_score(y_train, y_train_pred_classes),
            accuracy_score(y_test, y_test_pred_classes)
        ],
        'Precision': [
            precision_score(y_train, y_train_pred_classes, average='weighted'),
            precision_score(y_test, y_test_pred_classes, average='weighted')
        ],
        'Recall': [
            recall_score(y_train, y_train_pred_classes, average='weighted'),
            recall_score(y_test, y_test_pred_classes, average='weighted')
        ],
        'F1': [
            f1_score(y_train, y_train_pred_classes, average='weighted'),
            f1_score(y_test, y_test_pred_classes, average='weighted')
        ]
    }

    metrics_df = pd.DataFrame(metrics, index=['Train', 'Test'])

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    st.subheader("–ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫ –¥–ª—è Perceptron")
    col1, col2 = st.columns(2)
    with col1:
        plot_confusion_matrix(y_train, y_train_pred_classes, 'Train\nPerceptron')
    with col2:
        plot_confusion_matrix(y_test, y_test_pred_classes, 'Test\nPerceptron')

    # –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è
    st.subheader("–ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è")
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    ax1.plot(history.history['accuracy'], label='Train Accuracy')
    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')
    ax1.set_title('Accuracy')
    ax1.legend()

    ax2.plot(history.history['loss'], label='Train Loss')
    ax2.plot(history.history['val_loss'], label='Validation Loss')
    ax2.set_title('Loss')
    ax2.legend()

    st.pyplot(fig)

    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    train_results = pd.DataFrame({
        #'index': X_train.index,
        #'Actual': y_train,
        'Predicted': y_train_pred_classes
    })

    test_results = pd.DataFrame({
        #'index': X_test.index,
        #'Actual': y_test,
        'Predicted': y_test_pred_classes
    })

    return model, metrics_df, y_train_pred_classes, y_test_pred_classes
# ======== Models row ============
st.subheader("–ü–æ—è—Å–Ω–µ–Ω–∏—è –∫ –º–æ–¥–µ–ª—è–º –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º")

show_details = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—è—Å–Ω–µ–Ω–∏—è", value=True)

if show_details:
    with st.expander("üìö –ü–æ—è—Å–Ω–µ–Ω–∏—è –∫ –º–æ–¥–µ–ª—è–º –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º"):
        st.markdown("""
        ### –û–±—â–∏–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è –∫ —Ç—É–º–±–ª–µ—Ä–∞–º:
        * **–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å [–ù–∞–∑–≤–∞–Ω–∏–µ –ú–æ–¥–µ–ª–∏]!**: –≠—Ç–æ—Ç –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å –∑–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫—É –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –ï—Å–ª–∏ –æ–Ω –≤–∫–ª—é—á–µ–Ω, –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞, –æ–±—É—á–µ–Ω–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–º–µ—Ç—Ä–∏–∫–∏ –∏ –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫) –±—É–¥—É—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω—ã.

        ### –ü–æ—è—Å–Ω–µ–Ω–∏—è –∫ –º–æ–¥–µ–ª—è–º:

        #### **–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (Logistic Regression)**
        * **–ß—Ç–æ –¥–µ–ª–∞–µ—Ç**: –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è ‚Äî —ç—Ç–æ –ª–∏–Ω–µ–π–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**. –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ "—Ä–µ–≥—Ä–µ—Å—Å–∏—è", –æ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ –∫ –æ–¥–Ω–æ–º—É –∏–∑ –∫–ª–∞—Å—Å–æ–≤, –∞ –∑–∞—Ç–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç—Å—è –∫–ª–∞—Å—Å.
        * **–ó–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç**: –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω–æ–π –≥—Ä–∞–Ω–∏—Ü—ã —Ä–µ—à–µ–Ω–∏—è –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏. –•–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∑–∞–¥–∞—á –±–∏–Ω–∞—Ä–Ω–æ–π –∏ –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –∫–æ–≥–¥–∞ –∫–ª–∞—Å—Å—ã –ª–∏–Ω–µ–π–Ω–æ —Ä–∞–∑–¥–µ–ª–∏–º—ã –∏–ª–∏ –ø–æ—á—Ç–∏ —Ä–∞–∑–¥–µ–ª–∏–º—ã.
        * **–ö–∞–∫ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ –∫–æ–¥–µ)**:
            * `multi_class='multinomial'`: –£–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π (–µ—Å–ª–∏ —É –≤–∞—Å –±–æ–ª–µ–µ –¥–≤—É—Ö –∫–ª–∞—Å—Å–æ–≤).
            * `max_iter=1000`: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π, –∫–æ—Ç–æ—Ä–æ–µ –∞–ª–≥–æ—Ä–∏—Ç–º –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –¥–ª—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏. –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å –º–æ–¥–µ–ª–∏ —Å–æ–π—Ç–∏—Å—å, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–Ω–æ–≥–æ –∏–ª–∏ –æ–Ω–∏ —Å–ª–æ–∂–Ω—ã.

        #### **–î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π (Decision Tree)**
        * **–ß—Ç–æ –¥–µ–ª–∞–µ—Ç**: –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π ‚Äî —ç—Ç–æ –Ω–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è —Å —É—á–∏—Ç–µ–ª–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏** –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏. –û–Ω —Å—Ç—Ä–æ–∏—Ç –º–æ–¥–µ–ª—å –≤ –≤–∏–¥–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–µ—Ä–µ–≤–∞, –≥–¥–µ –∫–∞–∂–¥—ã–π –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —É–∑–µ–ª –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç "—Ç–µ—Å—Ç" –Ω–∞ –∞—Ç—Ä–∏–±—É—Ç–µ, –∫–∞–∂–¥–∞—è –≤–µ—Ç–≤—å ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∞, –∞ –∫–∞–∂–¥—ã–π –ª–∏—Å—Ç–æ–≤–æ–π —É–∑–µ–ª ‚Äî –º–µ—Ç–∫—É –∫–ª–∞—Å—Å–∞.
        * **–ó–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç**: –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –≤—ã—è–≤–ª–µ–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–∏–ª –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö. –î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ –ø–æ–Ω—è—Ç–Ω—ã –∏ —Ö–æ—Ä–æ—à–æ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è.
        * **–ö–∞–∫ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å**:
            * **`max_depth` (–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞)**: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≥–ª—É–±–∏–Ω—É –¥–µ—Ä–µ–≤–∞. –≠—Ç–æ –≤–∞–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è. –ë–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–æ–≥—É—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º –º–æ–¥–µ–ª—è–º –∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é.
            * **`min_samples_split` (–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è)**: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —É–∑–µ–ª –º–æ–≥ –±—ã—Ç—å —Ä–∞–∑–¥–µ–ª—ë–Ω. –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–µ–ª–∞–µ—Ç –¥–µ—Ä–µ–≤–æ –±–æ–ª–µ–µ "–ª–µ–Ω–∏–≤—ã–º" –∏ –º–µ–Ω–µ–µ —Å–∫–ª–æ–Ω–Ω—ã–º –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é.

        #### **–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å (Random Forest)**
        * **–ß—Ç–æ –¥–µ–ª–∞–µ—Ç**: –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å ‚Äî —ç—Ç–æ –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç—Ä–æ–∏—Ç –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ —Ä–µ—à–µ–Ω–∏–π –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞. –û–Ω —Å–Ω–∏–∂–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—É—é –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –¥–µ—Ä–µ–≤—å–µ–≤.
        * **–ó–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç**: –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ —É–ª—É—á—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –∑–∞ —Å—á–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ "—Å–ª–∞–±—ã—Ö" —É—á–∞—â–∏—Ö—Å—è (–¥–µ—Ä–µ–≤—å–µ–≤), —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö —Å–æ–≤–º–µ—Å—Ç–Ω–æ.
        * **–ö–∞–∫ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å**:
            * **`n_estimators` (–ß–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤)**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ —Ä–µ—à–µ–Ω–∏–π –≤ –ª–µ—Å—É. –ß–µ–º –±–æ–ª—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤, —Ç–µ–º –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–º –∏ —Ç–æ—á–Ω—ã–º –±—É–¥–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, –Ω–æ —Ç–µ–º –¥–æ–ª—å—à–µ –±—É–¥–µ—Ç –æ–±—É—á–µ–Ω–∏–µ.
            * **`max_depth` (–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞)**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞ –≤ –ª–µ—Å—É. –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–µ—Ä–µ–≤—É —Ä–µ—à–µ–Ω–∏–π, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –¥–µ—Ä–µ–≤—å–µ–≤.
            * **`min_samples_split` (–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è)**: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —É–∑–ª–∞ –≤ –∫–∞–∂–¥–æ–º –¥–µ—Ä–µ–≤–µ.

        #### **XGBoost (Extreme Gradient Boosting)**
        * **–ß—Ç–æ –¥–µ–ª–∞–µ—Ç**: XGBoost ‚Äî —ç—Ç–æ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –¥–ª—è **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏** –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏. –û–Ω–∞ —Å—Ç—Ä–æ–∏—Ç –¥–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –≥–¥–µ –∫–∞–∂–¥–æ–µ –Ω–æ–≤–æ–µ –¥–µ—Ä–µ–≤–æ –ø—ã—Ç–∞–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö.
        * **–ó–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç**: –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –º–æ—â–Ω—ã—Ö –∏ —Ç–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –æ—Å–æ–±–µ–Ω–Ω–æ –Ω–∞ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ò–∑–≤–µ—Å—Ç–µ–Ω —Å–≤–æ–µ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é.
        * **–ö–∞–∫ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å**:
            * **`learning_rate` (–¢–µ–º–ø –æ–±—É—á–µ–Ω–∏—è)**: –®–∞–≥, —Å –∫–æ—Ç–æ—Ä—ã–º –≤–µ—Å–∞ –Ω–æ–≤—ã—Ö –¥–µ—Ä–µ–≤—å–µ–≤ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –∫ –æ–±—â–µ–π –º–æ–¥–µ–ª–∏. –ú–µ–Ω—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–µ–ª–∞—é—Ç –æ–±—É—á–µ–Ω–∏–µ –±–æ–ª–µ–µ –º–µ–¥–ª–µ–Ω–Ω—ã–º, –Ω–æ —á–∞—Å—Ç–æ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –ª—É—á—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞—é—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ.
            * **`n_estimators` (–ß–∏—Å–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–π / –¥–µ—Ä–µ–≤—å–µ–≤)**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—É—Å—Ç–∏–Ω–≥–æ–≤—ã—Ö —Ä–∞—É–Ω–¥–æ–≤ –∏–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã. –ß–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –¥–æ–ª—å—à–µ –æ–±—É—á–µ–Ω–∏–µ, –Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤—ã—à–µ —Ç–æ—á–Ω–æ—Å—Ç—å.
            * **`max_depth` (–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞)**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –∫–∞–∂–¥–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–æ–≤–æ–≥–æ –¥–µ—Ä–µ–≤–∞. –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –¥–µ—Ä–µ–≤—å–µ–≤.

        #### **–ú–µ—Ç–æ–¥ –û–ø–æ—Ä–Ω—ã—Ö –í–µ–∫—Ç–æ—Ä–æ–≤ (SVC - Support Vector Classifier)**
        * **–ß—Ç–æ –¥–µ–ª–∞–µ—Ç**: SVC ‚Äî —ç—Ç–æ –º–æ—â–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –≥–∏–ø–µ—Ä–ø–ª–æ—Å–∫–æ—Å—Ç—å, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–∞–∑–¥–µ–ª—è—é—â—É—é –∫–ª–∞—Å—Å—ã –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        * **–ó–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç**: –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ "–Ω–∞–∏–ª—É—á—à–µ–π" –≥—Ä–∞–Ω–∏—Ü—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –µ–≥–æ —É—Å—Ç–æ–π—á–∏–≤—ã–º –∫ —à—É–º—É –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º –≤ –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞—Ö.
        * **–ö–∞–∫ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ –∫–æ–¥–µ)**:
            * SVC –∏–º–µ–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `C` –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏, `kernel` –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ñ—É–Ω–∫—Ü–∏–∏ —è–¥—Ä–∞, `gamma` –¥–ª—è –≤–ª–∏—è–Ω–∏—è –æ–¥–Ω–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π —Ç–æ—á–∫–∏). –í –¥–∞–Ω–Ω–æ–º –∫–æ–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–∞—á–∞–ª–∞. –î–ª—è –±–æ–ª–µ–µ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —ç—Ç–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

        #### **KNN-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (K-Nearest Neighbors Classifier)**
        * **–ß—Ç–æ –¥–µ–ª–∞–µ—Ç**: KNN ‚Äî —ç—Ç–æ –Ω–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç –Ω–æ–≤–æ–º—É –æ–±—ä–µ–∫—Ç—É –∫–ª–∞—Å—Å, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –≥–æ–ª–æ—Å–æ–≤ –µ–≥–æ `k` –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö.
        * **–ó–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç**: –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å —É–∂–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏. –û–Ω –ø—Ä–æ—Å—Ç –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–∏ –∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–º –Ω–∞ –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö.
        * **–ö–∞–∫ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å**:
            * **`n_neighbors` (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π)**: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ù–µ—á–µ—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è "–Ω–∏—á—å–∏—Ö" –≤ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ë–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–æ–≥—É—Ç —Å–≥–ª–∞–∂–∏–≤–∞—Ç—å –≥—Ä–∞–Ω–∏—Ü—É —Ä–µ—à–µ–Ω–∏—è, –º–µ–Ω—å—à–∏–µ - –¥–µ–ª–∞—Ç—å –µ–µ –±–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–π –∫ —à—É–º—É.

        #### **–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (Perceptron Classifier - –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å)**
        * **–ß—Ç–æ –¥–µ–ª–∞–µ—Ç**: –ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø—Ä–æ—Å—Ç–µ–π—à—É—é —Ñ–æ—Ä–º—É –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏, –∏–ª–∏ –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–π –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω (MLP). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**. –û–Ω —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è, –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤ –∏ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è, –≥–¥–µ –Ω–µ–π—Ä–æ–Ω—ã –≤ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ —Å–≤—è–∑–∞–Ω—ã —Å –Ω–µ–π—Ä–æ–Ω–∞–º–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ—è.
        * **–ó–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç**: –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∏–∑—É—á–µ–Ω–∏–µ —Å–ª–æ–∂–Ω—ã—Ö –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –≤ –¥–∞–Ω–Ω—ã—Ö –ø—É—Ç–µ–º –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–µ–≤ –Ω–µ–π—Ä–æ–Ω–æ–≤ —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏.
        * **–ö–∞–∫ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å**:
            * **`layers_target` (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤)**: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —Å–∫–æ–ª—å–∫–æ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤ –±—É–¥–µ—Ç –≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏. –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–µ–≤ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ –∏–∑—É—á–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏, –Ω–æ —Ç–∞–∫–∂–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∏ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è.
            * **`neurons_target` (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ —Å–ª–æ–µ)**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ –∫–∞–∂–¥–æ–º —Å–∫—Ä—ã—Ç–æ–º —Å–ª–æ–µ. –ë–æ–ª—å—à–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç "–µ–º–∫–æ—Å—Ç—å" –º–æ–¥–µ–ª–∏, –ø–æ–∑–≤–æ–ª—è—è –µ–π –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –Ω–æ —Ç–∞–∫–∂–µ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é.
            * **`learning_rate_target` (–¢–µ–º–ø –æ–±—É—á–µ–Ω–∏—è)**: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–∑–º–µ—Ä —à–∞–≥–∞, —Å –∫–æ—Ç–æ—Ä—ã–º –≤–µ—Å–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—Ç—Å—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è. –ú–∞–ª—ã–π —Ç–µ–º–ø –æ–±—É—á–µ–Ω–∏—è –º–æ–∂–µ—Ç –∑–∞–º–µ–¥–ª–∏—Ç—å —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å, –Ω–æ –ø–æ–º–æ—á—å –Ω–∞–π—Ç–∏ –±–æ–ª–µ–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ. –ë–æ–ª—å—à–æ–π —Ç–µ–º–ø –æ–±—É—á–µ–Ω–∏—è –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–æ–ø—É—Å–∫—É –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è.
            * **`epochs_target` (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö)**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª–Ω—ã—Ö –ø—Ä–æ—Ö–æ–¥–æ–≤ –ø–æ –≤—Å–µ–º—É —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º—É –Ω–∞–±–æ—Ä—É –¥–∞–Ω–Ω—ã—Ö. –ö–∞–∂–¥–∞—è —ç–ø–æ—Ö–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ —É—Ç–æ—á–Ω–∏—Ç—å —Å–≤–æ–∏ –≤–µ—Å–∞. –°–ª–∏—à–∫–æ–º –º–∞–ª–æ —ç–ø–æ—Ö –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—é, —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ ‚Äî –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é.

        ### –ü–æ—è—Å–Ω–µ–Ω–∏—è –∫ —Ç—É–º–±–ª–µ—Ä–∞–º "–ê–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π":

        * **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é (use_cv)**: –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω, –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –æ—Ü–µ–Ω–∏–≤–∞—Ç—å—Å—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö. –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—É—é –æ—Ü–µ–Ω–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏, —É—Å—Ä–µ–¥–Ω—è—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º "—Ñ–æ–ª–¥–∞–º" (–ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞–º –¥–∞–Ω–Ω—ã—Ö).
        * **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ (cv_folds)**: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ—Ç —Ä–∞–∑–±–∏—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, 5 —Ñ–æ–ª–¥–æ–≤ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç —Ä–∞–∑–±–∏—Ç—ã –Ω–∞ 5 —á–∞—Å—Ç–µ–π, –∏ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è 5 —Ä–∞–∑, –∫–∞–∂–¥—ã–π —Ä–∞–∑ –∏—Å–ø–æ–ª—å–∑—É—è –Ω–æ–≤—É—é —á–∞—Å—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ—Å—Ç–æ–≤–æ–π.
        * **–ú–µ—Ç–æ–¥ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è**:
            * **–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ (Voting)**: –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π. –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–Ω –≤—ã–±–∏—Ä–∞–µ—Ç –∫–ª–∞—Å—Å, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–æ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π (`'hard'` voting). –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± —É–ª—É—á—à–∏—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.
            * **–°—Ç—ç–∫–∏–Ω–≥ (Stacking)**: –ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –º–µ—Ç–æ–¥ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è. –û–Ω –æ–±—É—á–∞–µ—Ç "–º–µ—Ç–∞-–º–æ–¥–µ–ª—å" (–≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ, –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é) –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –¢–æ –µ—Å—Ç—å, –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–µ–ª–∞—é—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –∞ –∑–∞—Ç–µ–º —ç—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∫–∞–∫ –≤—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ "—É—á–∏—Ç—å—Å—è" –Ω–∞ –æ—à–∏–±–∫–∞—Ö –∏ —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω–∞—Ö –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π.
        """)
col1, col2, col3, col4, col5, col6, col7 = st.columns(7)
with col1:
  st.subheader("Logistic Regression")
  run_logreg = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –†–µ–≥—Ä–µ—Å—Å–∏–∏!")
  if run_logreg:
    model, metrics_df, y_train_pred, y_test_pred  = logistic_regression(X_train, X_test, y_train, y_test)
    logreg_model = model
    st.subheader("Metrics")
    st.dataframe(metrics_df)

    st.subheader("Train predictions")
    st.dataframe(pd.Series(y_train_pred).head())

    st.subheader("Test predictions")
    st.dataframe(pd.Series(y_test_pred).head())

with col2:
  st.subheader("Decision Tree")
  deps = st.text_input("max_depth", value = 10)
  minsamples = st.text_input("min_samples", value = 10)
  run_tree = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –¥–µ—Ä–µ–≤–∞!")
  if deps and minsamples and run_tree:
    model, metrics_df, y_train_pred, y_test_pred = tree(X_train, X_test, y_train, y_test, max_depth_target = eval(deps), min_samples_split_target = eval(minsamples))
    tree_model = model
    st.subheader("Metrics")
    st.dataframe(metrics_df)

    st.subheader("Train predictions")
    st.dataframe(pd.Series(y_train_pred).head())

    st.subheader("Test predictions")
    st.dataframe(pd.Series(y_test_pred).head())

with col3:
  st.subheader("Random Forest")
  rf_estimators = st.text_input("RF_estimators", value = 50)
  rf_deps = st.text_input("RF_max_depth", value = 10)
  rf_minsamples = st.text_input("RF_min_samples", value = 10)
  run_rf = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –°–ª—É—á–∞–π–Ω–æ–≥–æ –õ–µ—Å–∞!")
  if rf_estimators and rf_deps and rf_minsamples and run_rf:
    model, metrics_df, y_train_pred, y_test_pred = random_forest(X_train, X_test, y_train, y_test, estimators_target = eval(rf_estimators), max_depth_target = eval(rf_deps), min_samples_split_target = eval(rf_minsamples))
    rf_model = model
    st.subheader("Metrics")
    st.dataframe(metrics_df)

    st.subheader("Train predictions")
    st.dataframe(pd.Series(y_train_pred).head())

    st.subheader("Test predictions")
    st.dataframe(pd.Series(y_test_pred).head())

with col4:
  st.subheader("KNN")
  knn_neighbors = st.text_input("knn_neighbors_target", value = 10)
  run_knn = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å KNN!")
  if knn_neighbors and run_knn:
    model, metrics_df, y_train_pred, y_test_pred = knn_classifier(X_train, X_test, y_train, y_test, neighbors_target = eval(knn_neighbors))
    knn_model = model
    st.subheader("Metrics")
    st.dataframe(metrics_df)

    st.subheader("Train predictions")
    st.dataframe(pd.Series(y_train_pred).head())

    st.subheader("Test predictions")
    st.dataframe(pd.Series(y_test_pred).head())

with col5:
  st.subheader("XGBoost")
  xgb_learning_rate = st.text_input("xgb_learning_rate", value = 0.01)
  xgb_estimators = st.text_input("XGB_min_samples", value = 50)
  xgb_deps = st.text_input("XGB_max_depth", value = 10)
  run_xgb = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å XGBoost!")
  if run_xgb and xgb_learning_rate and xgb_estimators and xgb_deps:
    model, metrics_df, y_train_pred, y_test_pred = xgboost(X_train, X_test, y_train, y_test, learning_rate = eval(xgb_learning_rate), n_estimators = eval(xgb_estimators), max_depth = eval(xgb_deps))
    xgb_model = model
    st.subheader("Metrics")
    st.dataframe(metrics_df)

    st.subheader("Train predictions")
    st.dataframe(pd.Series(y_train_pred).head())

    st.subheader("Test predictions")
    st.dataframe(pd.Series(y_test_pred).head())

with col6:
  st.subheader("SVC")
  run_svc = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å SVC!")
  if run_svc:
    model, metrics_df, y_train_pred, y_test_pred = svc(X_train, X_test, y_train, y_test)
    svc_model = model
    st.subheader("Metrics")
    st.dataframe(metrics_df)

    st.subheader("Train predictions")
    st.dataframe(pd.Series(y_train_pred).head())

    st.subheader("Test predictions")
    st.dataframe(pd.Series(y_test_pred).head())


with col7:
  st.subheader("Perceptron")
  p_layers_target = st.text_input("layers_target", value = 2)
  p_neurons_target = st.text_input("neurons_target", value = 50)
  p_learning_rate_target = st.text_input("learning_rate_target", value = 0.01)
  p_epochs_target = st.text_input("epochs_target", value = 10)
  run_perceptron = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –ù–µ–∏—Ä–æ—Å–µ—Ç—å!")
  if p_layers_target and p_neurons_target and p_learning_rate_target and p_epochs_target and run_perceptron:
    model, metrics_df, y_train_pred, y_test_pred =  perceptron_classifier(X_train, X_test, y_train, y_test,
                          layers_target = eval(p_layers_target), neurons_target = eval(p_neurons_target), learning_rate_target = eval(p_learning_rate_target),
                          epochs_target = eval(p_epochs_target))
    perceptron_model = model
    st.subheader("Metrics")
    st.dataframe(metrics_df)

    st.subheader("Train predictions")
    st.dataframe(pd.Series(y_train_pred).head())

    st.subheader("Test predictions")
    st.dataframe(pd.Series(y_test_pred).head())

# ======= –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ =======
available_functions = {
    '–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è': logistic_regression,
    '–î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π': tree,
    '–†–∞–Ω–¥–æ–º–Ω—ã–π –ª–µ—Å': random_forest,
    'XGboost': xgboost,
    '–ú–µ—Ç–æ–¥ –û–ø–æ—Ä–Ω—ã—Ö –í–µ–∫—Ç–æ—Ä–æ–≤': svc,
    'KNN-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä': knn_classifier,
    '–ü–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä': perceptron_classifier
}

use_cv = st.sidebar.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é", value=False)
cv_folds = st.sidebar.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤", 2, 10, 5)

# –ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ

def voting_ensemble(models, X_train, X_test, y_train, y_test):
    """
    –ê–Ω—Å–∞–º–±–ª—å –º–µ—Ç–æ–¥–æ–º –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è
    """
    voting = VotingClassifier(
        estimators=[(name, model) for name, model in models.items()],
        voting='hard'
    )
    voting.fit(X_train, y_train)
    return evaluate_model(voting, X_train, X_test, y_train, y_test, "Voting Ensemble")

def stacking_ensemble(models, X_train, X_test, y_train, y_test):
    """
    –ê–Ω—Å–∞–º–±–ª—å –º–µ—Ç–æ–¥–æ–º —Å—Ç—ç–∫–∏–Ω–≥–∞
    """
    stacking = StackingClassifier(
        estimators=[(name, model) for name, model in models.items()],
        final_estimator=LogisticRegression(max_iter=1000),
        cv=5
    )
    stacking.fit(X_train, y_train)
    return evaluate_model(stacking, X_train, X_test, y_train, y_test, "Stacking Ensemble")

st.title("–ê–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π")

# –°–æ–±–∏—Ä–∞–µ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
built_models = {}
if 'logreg_model' in globals():
    built_models['Logistic Regression'] = logreg_model
if 'tree_model' in globals():
    built_models['Decision Tree'] = tree_model
if 'rf_model' in globals():
    built_models['Random Forest'] = rf_model
if 'xgb_model' in globals():
    built_models['XGBoost'] = xgb_model
if 'svc_model' in globals():
    built_models['SVC'] = svc_model
if 'knn_model' in globals():
    built_models['KNN'] = knn_model
if 'perceptron_model' in globals():
    built_models['Perceptron'] = perceptron_model

if not built_models:
    st.warning("–ü–æ—Å—Ç—Ä–æ–π—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –∞–Ω—Å–∞–º–±–ª—è")
    st.stop()

# –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è
selected_models = st.multiselect(
    "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è (..–Ω–æ –Ω–µ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω)",
    options=list(built_models.keys()),
    default=list(built_models.keys())
)

if len(selected_models) < 2:
    st.warning("–î–ª—è –∞–Ω—Å–∞–º–±–ª—è –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å —Ö–æ—Ç—è –±—ã 2 –º–æ–¥–µ–ª–∏")
    st.stop()

# –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
ensemble_method = st.selectbox(
    "–ú–µ—Ç–æ–¥ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è",
    ["–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ", "–°—Ç—ç–∫–∏–Ω–≥"],
    index=0
)

# –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–Ω—Å–∞–º–±–ª—è
if st.checkbox("–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∞–Ω—Å–∞–º–±–ª—å"):
    # –°–æ–±–∏—Ä–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
    models_to_ensemble = {name: built_models[name] for name in selected_models}

    with st.spinner("–°—Ç—Ä–æ–∏–º –∞–Ω—Å–∞–º–±–ª—å..."):
        if ensemble_method == "–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ":
            model, metrics, train_pred, test_pred = voting_ensemble(
                models_to_ensemble, X_train, X_test, y_train, y_test
            )
        else:
            model, metrics, train_pred, test_pred = stacking_ensemble(
                models_to_ensemble, X_train, X_test, y_train, y_test
            )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        ensemble_model = model
        ensemble_metrics = metrics
        ensemble_train_pred = train_pred
        ensemble_test_pred = test_pred

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.success("–ê–Ω—Å–∞–º–±–ª—å —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω!")

        st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –∞–Ω—Å–∞–º–±–ª—è")
        st.dataframe(metrics.style.format("{:.2%}"))

        st.subheader("Train predictions")
        st.dataframe(pd.DataFrame({
            'Actual': y_train,
            'Predicted': train_pred
        }).head())

        st.subheader("Test predictions")
        st.dataframe(pd.DataFrame({
            'Actual': y_test,
            'Predicted': test_pred
        }).head())
# –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º –º–æ–¥–µ–ª—è–º —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏ –≤—ã–≥—Ä—É–∑–∫–æ–π
st.title("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")

new_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (CSV –∏–ª–∏ Excel)", type=["csv", "xlsx"])

if new_file:
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
    if new_file.name.endswith('.csv'):
        new_data = pd.read_csv(new_file, sep=sep_sign, decimal=decimal_sign)
    else:
        new_data = pd.read_excel(new_file)

    st.success(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(new_data)} –∑–∞–ø–∏—Å–µ–π")
    st.dataframe(new_data.head())

    # 2. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    st.header("–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö")

    try:
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ –∂–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, —á—Ç–æ –∏ –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º
        processed_data = new_data.copy()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        new_data_processed = handle_missing_values(processed_data, method)

        st.success("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
        st.dataframe(new_data_processed.head())

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        st.stop()

    with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
        # –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º
        X_train_new, X_test_new, y_train_new, y_test_new, train_ids_new, test_ids_new = preprocess_data(
            data=new_data_processed,
            target_col=target_col,
            id_cols=id_cols,
            features=selected_features,
            norm_cols=norm_cols,
            log_cols=log_cols,
            dummy_cols=dummy_cols,
            balance_method=balance_method,
            test_size=0.1,
            random_state=random_state
        )
    new_preprocess_data = np.vstack([X_train_new, X_test_new])

    # 3. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    st.header("3. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

    available_models = built_models

    if not available_models:
        st.warning("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ—Å—Ç—Ä–æ–π—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –º–æ–¥–µ–ª—å.")
        st.stop()

    selected_models = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è",
        options=list(available_models.keys()),
        default=list(available_models.keys())
    )

    # 4. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    if st.checkbox("–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"):
        predictions = pd.DataFrame(index=pd.DataFrame(new_preprocess_data).index)

        for model_name in selected_models:
            model = available_models[model_name]

            try:
                # –û—Å–æ–±—ã–π —Å–ª—É—á–∞–π –¥–ª—è XGBoost (–Ω—É–∂–Ω–æ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫)
                if model_name == 'XGBoost':
                    if label_encoder not in globals():
                        st.error("–ù–µ –Ω–∞–π–¥–µ–Ω –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –º–µ—Ç–æ–∫ –¥–ª—è XGBoost")
                        continue

                    le = st.session_state.label_encoder
                    pred = model.predict(new_preprocess_data)
                    predictions[model_name] = le.inverse_transform(pred)

                # –û—Å–æ–±—ã–π —Å–ª—É—á–∞–π –¥–ª—è –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞
                elif model_name == 'Perceptron':
                    if perceptron_encoder not in globals():
                        st.error("–ù–µ –Ω–∞–π–¥–µ–Ω –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –º–µ—Ç–æ–∫ –¥–ª—è –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞")
                        continue

                    le = perceptron_encoder
                    pred_proba = model.predict(new_preprocess_data)
                    pred = np.argmax(pred_proba, axis=1)
                    predictions[model_name] = le.inverse_transform(pred)

                # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                else:
                    predictions[model_name] = model.predict(new_preprocess_data)

            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ —Å –ø–æ–º–æ—â—å—é {model_name}: {str(e)}")
                continue

        # –î–æ–±–∞–≤–ª—è–µ–º –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ, –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π
        if len(selected_models) > 1:
            def majority_vote(row):
                votes = [row[model] for model in selected_models]
                return Counter(votes).most_common(1)[0][0]

            predictions['Majority_Vote'] = predictions.apply(majority_vote, axis=1)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = predictions

        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
        st.dataframe(predictions)

        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        csv = predictions.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="–°–∫–∞—á–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞–∫ CSV",
            data=csv,
            file_name='predictions.csv',
            mime='text/csv'
        )
