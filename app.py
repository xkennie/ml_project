### OVERALL CODE
#–ª–∏–±—ã
#–±–∞–∑–∞
#!pip install streamlit
#!pip install ydata-profiling

import os
import numpy as np
import pandas as pd
import streamlit as st
from sklearn.model_selection import train_test_split
#from ydata_profiling import ProfileReport
import inspect
from collections import Counter
import seaborn as sns
import matplotlib.pyplot as plt
#classification models
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import LabelEncoder, StandardScaler
import keras
from tensorflow.keras.optimizers import Adam
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical
st.set_page_config(page_title="HSE | –¢–ò–ò–ü–ê", layout="wide")

st.title("¬© HSE | –¢–ò–ò–ü–ê")
st.markdown("**Fast-touch classification-analytical tool**")

st.markdown("---")

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º–∞–Ω–¥–µ
with st.expander("‚Ñπ–û –∫–æ–º–∞–Ω–¥–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤"):
    st.markdown("""
    **–ö–æ–º–∞–Ω–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞:**
    - –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ò–ª—å—è—â–µ–Ω–∫–æ ‚Äî Team Leader
    - –í–∞–¥–∏–º –ö–∞–∑–∞–∫–æ–≤ ‚Äî Master of Machine Learning
    - –ê–Ω–¥—Ä–µ–π –®–∏—Ä—à–æ–≤ ‚Äî Business Developer
    - –¢–∞—Ç—å—è–Ω–∞ –ß–µ—Ä–Ω—ã—Ö ‚Äî Designer
    """)

# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
with st.expander("–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Å–µ—Ä–≤–∏—Å–∞", expanded=True):
    st.markdown("""
    1. *–í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω—É—é —Ç–µ–º—É* –∞–Ω–∞–ª–∏–∑–∞
    2. *–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ* —Å –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    3. *–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ* –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    4. *–ó–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑* ‚Äî –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –¥–æ–≤–µ—Ä—å—Ç–µ—Å—å –Ω–∞–º. *–î–∞–π—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º—É –≤—Ä–µ–º—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.*
    5. *–ò–∑—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã* ‚Äî –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.
    6. *–í—ã–±–µ—Ä–∏—Ç–µ* –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏ *–ø—Ä–∏–º–µ–Ω–∏—Ç–µ* –µ—ë –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    """)

st.markdown("---")

#st.title("–ó–∞–≥—Ä—É–∑–∏ —Ñ–∞–π–ª —Å—é–¥–∞, –¥—Ä—É–≥")
#uploaded_file = st.file_uploader("Select a CSV file", type=["csv"])
st.title("–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª (CSV –∏–ª–∏ Excel)", type=["csv", "xls", "xlsx"])

if uploaded_file is not None:
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
    file_name = uploaded_file.name.lower()

    if file_name.endswith('.csv'):
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è CSV —Ñ–∞–π–ª–æ–≤
        sep_sign = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å",
            (";", ",", " ", "|"), index=0)

        decimal_sign = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç–¥–µ–ª–∏—Ç–µ–ª—å –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏",
            (".", ","), index=1)

        df = pd.read_csv(uploaded_file, sep=sep_sign, decimal=decimal_sign)

    elif file_name.endswith(('.xls', '.xlsx')):
        df = pd.read_excel(uploaded_file)

    st.write("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö:")
    st.dataframe(df.head())
    backup_df = df.copy()
 
#if uploaded_file is not None:
  #seps = [";", ","]
  #decimals = [".", ","]
  #sep_sign = ";"
  #sep_sign = st.selectbox(
   # "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å",
   # (";", ",", " ", "/"))
  #decimal_sign = ","
  #decimal_sign = st.selectbox(
    #"–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç–¥–µ–ª–∏—Ç–µ–ª—å –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏",
    #(".", ","))
  #df = pd.read_csv(uploaded_file, sep = sep_sign, decimal = decimal_sign)
  #st.write("–¢–≤–æ–π –¥–∞—Ç–∞—Å–µ—Ç:")
  #st.dataframe(df.head())
  #backup_df = df.copy()


#—á—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
#def read_data(df):
  #return df
#def handle_missing_values(df, option):

    #df_processed = df.copy()
    
    #if option == "–î—Ä–æ–ø–Ω—É—Ç—å":
        #df_processed = df_processed.dropna()
    #elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å":
        #for col in df_processed.columns:
            #if pd.api.types.is_numeric_dtype(df_processed[col]):
                #df_processed[col] = df_processed[col].fillna(0)
            #else:
                #df_processed[col] = df_processed[col].fillna("0")
    #elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–µ–¥–∏–∞–Ω—É":
        #for col in df_processed.columns:
            #if pd.api.types.is_numeric_dtype(df_processed[col]):
                #median_val = df_processed[col].median()
                #df_processed[col] = df_processed[col].fillna(median_val)
            #else:
                #df_processed[col] = df_processed[col].fillna("0")
    
    #return df_processed
# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ Streamlit
def handle_missing_values(df, option, categorical_method="mode"):
    df_processed = df.copy()

    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
    for col in df_processed.columns:
        # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if pd.api.types.is_numeric_dtype(df_processed[col]):
            if option == "–£–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏":
                df_processed = df_processed.dropna(subset=[col])
            elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å":
                df_processed[col] = df_processed[col].fillna(0)
            elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–µ–¥–∏–∞–Ω—É":
                df_processed[col] = df_processed[col].fillna(df_processed[col].median())
            elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ":
                df_processed[col] = df_processed[col].fillna(df_processed[col].mean())
            elif option == "–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è":
                df_processed[col] = df_processed[col].interpolate()

        # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        else:
            if option == "–£–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏":
                df_processed = df_processed.dropna(subset=[col])
            elif option == "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–æ–¥—É":
                df_processed[col] = df_processed[col].fillna(df_processed[col].mode()[0])
            elif option == "–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é 'Unknown'":
                df_processed[col] = df_processed[col].fillna("Unknown")
            elif option == "–≠–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è (–ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)":
                df_processed[col] = df_processed[col].fillna(method='fill')

    return df_processed
st.title("–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ")

# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é df
if 'df' not in globals():
    st.warning("–î–∞—Ç–∞—Ñ—Ä–µ–π–º –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–∞–º—è—Ç–∏. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
    st.stop()
# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–ø—É—Å–∫–∞—Ö
st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
missing_stats = df.isna().sum()
missing_percent = (missing_stats / len(df)) * 100
missing_df = pd.DataFrame({
    "–ö–æ–ª–æ–Ω–∫–∞": missing_stats.index,
    "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤": missing_stats.values,
    "–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤": missing_percent.values.round(2)
})
st.dataframe(missing_df)

# –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
st.markdown("---")
st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤")

col1, col2 = st.columns(2)
with col1:
    method = st.selectbox(
        "–ú–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤:",
        options=[
            "–£–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏",
            "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å",
            "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–µ–¥–∏–∞–Ω—É",
            "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ",
            "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–æ–¥—É",
            "–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é 'Unknown'",
            "–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è",
            "–≠–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è (–ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)"
        ],
        index=2,
        help="–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"
    )

with col2:
    show_details = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—è—Å–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤", value=True)

if show_details:
    with st.expander("üìö –ü–æ—è—Å–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏"):
        st.markdown("""
        - **–£–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏** - –ø–æ–ª–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö –ø—Ä–æ–ø—É—Å–∫–∏
        - **–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å** - –∑–∞–º–µ–Ω–∞ –≤—Å–µ—Ö –ø—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–∞ 0 (–¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
        - **–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–µ–¥–∏–∞–Ω—É** - –∑–∞–º–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –º–µ–¥–∏–∞–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (—É—Å—Ç–æ–π—á–∏–≤–æ –∫ –≤—ã–±—Ä–æ—Å–∞–º)
        - **–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ** - –∑–∞–º–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ —Å—Ä–µ–¥–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (–º–æ–∂–µ—Ç –∏—Å–∫–∞–∂–∞—Ç—å—Å—è –≤—ã–±—Ä–æ—Å–∞–º–∏)
        - **–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–æ–¥—É** - –∑–∞–º–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (–¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
        - **–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é 'Unknown'** - –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–ø—É—Å–∫–µ
        - **–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è** - –ª–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π (–¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)
        - **–≠–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è** - –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏–º –∏–∑–≤–µ—Å—Ç–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (–º–µ—Ç–æ–¥ 'forward fill')
        """)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
if st.button("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", type="primary"):
    with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
        df = handle_missing_values(df, method)
        st.success("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.markdown("---")
        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        col1, col2 = st.columns(2)
        with col1:
            st.metric("–ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫", len(backup_df))
        with col2:
            st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏", len(df))

        st.dataframe(df.head(10))
# –í—ã–ø–∞–¥–∞—é—â–∏–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–µ—Ç–æ–¥–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤
#missing_values_option = st.selectbox(
    #"–ß—Ç–æ –¥–µ–ª–∞—Ç—å —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏?",
    #options=["–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å", "–î—Ä–æ–ø–Ω—É—Ç—å", "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –º–µ–¥–∏–∞–Ω—É"],
    #index=0  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–±—Ä–∞–Ω "–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω–æ–ª—å"
#)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞
#df = handle_missing_values(df, missing_values_option)

# –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
#st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏")
#st.write(f"–í—ã–±—Ä–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥: {missing_values_option}")
#st.write(f"–ò—Å—Ö–æ–¥–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(backup_df)}")
#st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(df)}")
#df = st.session_state.df
# –ü–æ–∫–∞–∑–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
st.dataframe(df)

#–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ —Ä–∞–±–æ—Ç–æ–π
st.title("–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")

st.write(df.describe())

st.header("–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")

# –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
st.title("–í–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
st.markdown("---")

with st.expander("–û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö", expanded=True):
    st.subheader("–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

    # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ describe()
    desc = df.describe().T
    desc['missing'] = df.isna().sum()
    desc['missing_percent'] = (desc['missing'] / len(df)).round(2)
    desc['dtype'] = df.dtypes
    desc['unique'] = df.nunique()

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—ã–≤–æ–¥
    st.dataframe(
        desc.style.format({
            'mean': '{:.2f}',
            'std': '{:.2f}',
            'min': '{:.2f}',
            '25%': '{:.2f}',
            '50%': '{:.2f}',
            '75%': '{:.2f}',
            'max': '{:.2f}',
            'missing_percent': '{:.0%}'
        }),
        use_container_width=True
    )

st.markdown("---")
st.header("–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è")

# –í—ã–±–æ—Ä —Ç–∏–ø–∞ –≥—Ä–∞—Ñ–∏–∫–∞
chart_type = st.radio(
    "–¢–∏–ø –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:",
    ["–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞", "–Ø—â–∏–∫ —Å —É—Å–∞–º–∏ (Boxplot)", "–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"],
    horizontal=True
)

col1, col2 = st.columns([3, 1])
with col1:
    selected_col = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
        options=df.select_dtypes(include=['number']).columns,
        index=0
    )

with col2:
    if chart_type == "–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞":
        bins = st.slider(
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤:",
            min_value=5,
            max_value=50,
            value=int(np.sqrt(len(df)) if len(df) > 0 else 20)
        )

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞
fig, ax = plt.subplots(figsize=(10, 5))

if chart_type == "–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞":
    sns.histplot(df[selected_col], bins=bins, kde=True, ax=ax)
    ax.set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {selected_col}')
    ax.set_xlabel(selected_col)
    ax.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
elif chart_type == "–Ø—â–∏–∫ —Å —É—Å–∞–º–∏ (Boxplot)":
    sns.boxplot(x=df[selected_col], ax=ax)
    ax.set_title(f'Boxplot –¥–ª—è {selected_col}')
elif chart_type == "–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è":
    sns.kdeplot(df[selected_col], ax=ax, fill=True)
    ax.set_title(f'–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è {selected_col}')
    ax.set_xlabel(selected_col)
    ax.set_ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å')

st.pyplot(fig)

st.markdown("---")
    # 1. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏
st.subheader("–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞")
selected_col = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã",
        options=df.columns,
        index=2
    )
hist_values = np.histogram(df[selected_col], bins=int(round( len(df[selected_col])**0.5 ,0)))
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame –¥–ª—è st.bar_chart
hist_df = pd.DataFrame({
        'bin_left': hist_values[1][:-1],
        'bin_right': hist_values[1][1:],
        'count': hist_values[0]
    })
hist_df['bin'] = hist_df.apply(lambda x: f"{x['bin_left']:.2f}-{x['bin_right']:.2f}", axis=1)
    
# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –±–∞—Ä—á–∞—Ä—Ç
st.bar_chart(hist_df.set_index('bin')['count'])
    
    # 2. Scatter plot —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
st.subheader("Scatter plot")
col1, col2, col3, col4 = st.columns(4)
    
with col1:
  x_axis = st.selectbox(
            "–û—Å—å X",
            options=df.columns,
            index=0
        )
with col2:
  y_axis = st.selectbox(
            "–û—Å—å Y",
            options=df.columns,
            index=1 if len(df.columns) > 1 else 0
        )
    
with col3:
  color_col = st.selectbox(
            "–¶–≤–µ—Ç",
            options=["None"] + list(df.columns),
            index=0
        )
with col4:
  size_col = st.selectbox(
            "–†–∞–∑–º–µ—Ä",
            options=["None"] + list(df.columns),
            index=0
        )    
if (color_col == "None") & (size_col == "None"):
    st.scatter_chart(df, x=x_axis, y=y_axis)
elif (size_col == "None") & (color_col != "None"):
    st.scatter_chart(df, x=x_axis, y=y_axis, color=color_col)
elif (size_col != "None") & (color_col == "None"):
    st.scatter_chart(df, x=x_axis, y=y_axis, size = size_col)
elif (size_col != "None") & (color_col != "None"):
    st.scatter_chart(df, x=x_axis, y=y_axis, color = color_col, size = size_col)

st.subheader("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    # 1. –í—ã–±–æ—Ä —Ç–∞—Ä–≥–µ—Ç–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (y)
target_col = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∞—Ä–≥–µ—Ç–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (y)",
        options=df.columns,
        index=0,  # –î–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –ø–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞
        key="target_select"
    )
    
    # 2. –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (X) - –∏—Å–∫–ª—é—á–∞–µ–º —Ç–∞—Ä–≥–µ—Ç –∏–∑ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
available_features = [col for col in df.columns if col != target_col]
    
selected_features = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ (X)",
        options=available_features,
        default=available_features,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        key="features_select"
    )
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –≤—ã–±—Ä–∞–Ω—ã —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫
if not selected_features:
  st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –º–æ–¥–µ–ª–∏")
      
if selected_features:    
    # –§–æ—Ä–º–∏—Ä—É–µ–º X –∏ y
  y = df[target_col]
  X = df[selected_features]
    
    # 3. –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ train/test
  X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=0.2, 
        random_state=42
    )
    
    # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–±–∏–µ–Ω–∏–∏
  st.success("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã!")
  st.write(f"–í—ã–±—Ä–∞–Ω —Ç–∞—Ä–≥–µ—Ç: {target_col}")
  st.write(f"–í—ã–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)}")
  st.write(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X_train.shape[0]}")
  st.write(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_test.shape[0]}")
def preprocess(X_train, X_test, y_train, y_test):
  return X_train, X_test, y_train, y_test
    
#—Ñ—É–Ω–∫—Ü–∏–∏ —Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è–º–∏ –º–µ—Ç–æ–¥–æ–≤ ML
X_train, X_test, y_train, y_test = preprocess(X_train, X_test, y_train, y_test)
  
#logreg
def logistic_regression(X_train, X_test, y_train, y_test):
  X_train, X_test, y_train, y_test = preprocess(X_train, X_test, y_train, y_test)
  logreg = LogisticRegression(
    multi_class='multinomial',
    max_iter = 1000
)
  logreg.fit(X_train, y_train)
  y_pred = logreg.predict(X_test)
  predict = pd.Series(y_pred)
  logreg_predicts = pd.concat([y_test.reset_index(), predict], axis = 1)
  logreg_predicts.columns = ['index', 'Style', 'Logreg_predict']
  return logreg_predicts

#tree
def tree(X_train, X_test, y_train, y_test, max_depth_target = 10, min_samples_split_target = 10):
  X_train, X_test, y_train, y_test = preprocess(X_train, X_test, y_train, y_test)
  tree = DecisionTreeClassifier(
    max_depth = max_depth_target,             # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞
    min_samples_split = min_samples_split_target,     # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
)
  tree.fit(X_train, y_train)
  y_pred = tree.predict(X_test)
  #y_pred_train = tree.predict(X_train)
  predict = pd.Series(y_pred)
  tree_predicts = pd.concat([y_test.reset_index(), predict], axis = 1)
  #tree_predicts = tree_predicts.replace({0: 'predict'})
  tree_predicts.columns = ['index', 'Style', 'Tree_predict']
  #return tree_train_predicts, tree_predicts
  return tree_predicts

#forest
def random_forest(X_train, X_test, y_train, y_test, estimators_target = 50, max_depth_target = 10, min_samples_split_target = 10):
  X_train, X_test, y_train, y_test = preprocess(X_train, X_test, y_train, y_test)
  random_forest = RandomForestClassifier(
    n_estimators = estimators_target,  # –ß–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤
    max_features='sqrt', 
    max_depth = max_depth_target,
    min_samples_split = min_samples_split_target
)
  random_forest.fit(X_train, y_train)
  y_pred = random_forest.predict(X_test)
  predict = pd.Series(y_pred)
  random_forest_predicts = pd.concat([y_test.reset_index(), predict], axis = 1)
  random_forest_predicts.columns = ['index', 'Style', 'Random_Forest_predict']
  return random_forest_predicts

#xgboost
def xgboost(X_train, X_test, y_train, y_test, learning_rate_target = 0.01, estimators_target = 50, max_depth_target = 10):
  X_train, X_test, y_train, y_test = preprocess(X_train, X_test, y_train, y_test)
  le = LabelEncoder()
  y_train = le.fit_transform(y_train)
  xgboost = XGBClassifier(
    n_estimators = estimators_target,
    max_depth = max_depth_target,
    learning_rate = learning_rate_target,
    random_state = 42
)
  xgboost.fit(X_train, y_train)
  y_pred = xgboost.predict(X_test)
  y_pred = le.inverse_transform(y_pred)
  predict = pd.Series(y_pred)
  xgboost_predicts = pd.concat([y_test.reset_index(), predict], axis = 1)
  xgboost_predicts.columns = ['index', 'Style', 'XGBoost_predict']
  return xgboost_predicts

#Support-vector-calc
def svc(X_train, X_test, y_train, y_test):
  X_train, X_test, y_train, y_test = preprocess(X_train, X_test, y_train, y_test)
  svc = SVC()
  svc.fit(X_train, y_train)
  y_pred = svc.predict(X_test)
  predict = pd.Series(y_pred)
  svc_predicts = pd.concat([y_test.reset_index(), predict], axis = 1)
  svc_predicts.columns = ['index', 'Style', 'SVC_predict']
  return svc_predicts
#knn
def knn_classifier(X_train, X_test, y_train, y_test, neighbors_target = 10):
  X_train, X_test, y_train, y_test = preprocess(X_train, X_test, y_train, y_test)
  knn = KNeighborsClassifier(n_neighbors= neighbors_target)
  knn.fit(X_train, y_train)
  y_pred = knn.predict(X_test)
  predict = pd.Series(y_pred)
  knn_predicts = pd.concat([y_test.reset_index(), predict], axis = 1)
  knn_predicts.columns = ['index', 'Style', 'KNN_predict']
  return knn_predicts

def perceptron_classifier(X_train, X_test, y_train, y_test,
                          layers_target = 2, neurons_target = 50, learning_rate_target = 0.01,
                          epochs_target = 10):
  X_train, X_test, y_train, y_test = preprocess(X_train, X_test, y_train, y_test)
  #y_train encode
  label_encoder = LabelEncoder()
  y_encoded = label_encoder.fit_transform(y_train)
  y_train = to_categorical(y_encoded)  
  #y_test encode
  y_encoded = label_encoder.fit_transform(y_test)
  y_test = to_categorical(y_encoded)

  perceptron = Sequential()
  for n in range(layers_target):
    perceptron.add(Dense(neurons_target, input_dim = X_train.shape[1], activation = 'relu'))  # –°–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏
  
  perceptron.add(Dense(y_train.shape[1], activation = 'softmax'))  # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π


  perceptron.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate = learning_rate_target), metrics=['accuracy'])

  perceptron.fit(X_train, y_train, epochs= epochs_target, batch_size=10, validation_data=(X_test, y_test))

  predictions = perceptron.predict(X_test)
  predicted_classes = np.argmax(predictions, axis=1)
  predicted_styles = label_encoder.inverse_transform(predicted_classes)
  predict = pd.Series(predicted_styles)

  true_class = np.argmax(y_test, axis = 1)
  true_styles = label_encoder.inverse_transform(true_class)
  y_true = pd.Series(true_styles)

  perceptron_predicts = pd.concat([y_true, predict], axis = 1)
  perceptron_predicts.columns = ['Style', 'Perceptron_predict']
  perceptron_predicts["index"] = [i for i in range(perceptron_predicts.shape[0])]
  perceptron_predicts = perceptron_predicts[["index", "Style", "Perceptron_predict"]]                        
  return perceptron_predicts
# ======== Models row ============
col1, col2, col3, col4, col5, col6, col7 = st.columns(7)
with col1:
  st.subheader("Logistic Regression")
  run_logreg = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –†–µ–≥—Ä–µ—Å—Å–∏–∏!")
  if run_logreg:
    #_, result = logistic_regression(X_train, X_test, y_train, y_test)
    result = logistic_regression(X_train, X_test, y_train, y_test)
    acc = (result['Logreg_predict'] == result['Style']).mean()
    st.write(f"Accuracy: {acc:.2%}")
    st.write(result)
    
with col2:
  st.subheader("Tree")
  deps = st.text_input("max_depth", value = 10)
  minsamples = st.text_input("min_samples", value = 10)
  run_tree = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –¥–µ—Ä–µ–≤–∞!")
  if deps and minsamples and run_tree:
    result = tree(X_train, X_test, y_train, y_test, max_depth_target = eval(deps), min_samples_split_target = eval(minsamples))
    acc = (result['Tree_predict'] == result['Style']).mean()
    st.write(f"Accuracy: {acc:.2%}")
    st.write(result)

    
with col3:
  st.subheader("Random Forest")
  rf_estimators = st.text_input("RF_estimators", value = 50)
  rf_deps = st.text_input("RF_max_depth", value = 10)
  rf_minsamples = st.text_input("RF_min_samples", value = 10)
  run_rf = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –°–ª—É—á–∞–π–Ω–æ–≥–æ –õ–µ—Å–∞!")
  if rf_estimators and rf_deps and rf_minsamples and run_rf:
    result = random_forest(X_train, X_test, y_train, y_test, estimators_target = eval(rf_estimators), max_depth_target = eval(rf_deps), min_samples_split_target = eval(rf_minsamples))
    acc = (result['Random_Forest_predict'] == result['Style']).mean()
    st.write(f"Accuracy: {acc:.2%}")
    st.write(result)

with col4:
  st.subheader("XGBoost")
  xgb_learning_rate = st.text_input("XGB_max_depth", value = 0.01)
  xgb_estimators = st.text_input("XGB_min_samples", value = 50)
  xgb_deps = st.text_input("XGB_max_depth", value = 10)
  run_xgb = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å XGBoost!")
  if run_xgb and xgb_learning_rate and xgb_estimators and xgb_deps:
    result = xgboost(X_train, X_test, y_train, y_test, learning_rate_target = eval(xgb_learning_rate), estimators_target = eval(xgb_estimators), max_depth_target = eval(xgb_deps))
    acc = (result['XGBoost_predict'] == result['Style']).mean()
    st.write(f"Accuracy: {acc:.2%}")
    st.write(result)

with col5:
  st.subheader("SVC")
  run_svc = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å SVC!")
  if run_svc:
    result = svc(X_train, X_test, y_train, y_test)
    acc = (result['SVC_predict'] == result['Style']).mean()
    st.write(f"Accuracy: {acc:.2%}")
    st.write(result)

with col6:
  st.subheader("KNN")
  knn_neighbors = st.text_input("knn_neighbors_target", value = 10)
  run_knn = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å KNN!")
  if knn_neighbors and run_knn:
    result = knn_classifier(X_train, X_test, y_train, y_test, neighbors_target = eval(knn_neighbors))
    acc = (result['KNN_predict'] == result['Style']).mean()
    st.write(f"Accuracy: {acc:.2%}")
    st.write(result)
    
with col7:
  st.subheader("Perceptron")
  p_layers_target = st.text_input("layers_target", value = 2)
  p_neurons_target = st.text_input("neurons_target", value = 50)
  p_learning_rate_target = st.text_input("learning_rate_target", value = 0.01)
  p_epochs_target = st.text_input("epochs_target", value = 10)
  run_perceptron = st.checkbox("–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –ù–µ–∏—Ä–æ—Å–µ—Ç—å!")
  if p_layers_target and p_neurons_target and p_learning_rate_target and p_epochs_target and run_perceptron:
    result =  perceptron_classifier(X_train, X_test, y_train, y_test,
                          layers_target = eval(p_layers_target), neurons_target = eval(p_neurons_target), learning_rate_target = eval(p_learning_rate_target),
                          epochs_target = eval(p_epochs_target)) 
    acc = (result['Perceptron_predict'] == result['Style']).mean()
    st.write(f"Accuracy: {acc:.2%}")
    st.write(result)

# ======= –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ =======
available_functions = {
    'logistic_regression': logistic_regression,
    'tree': tree,
    'random_forest': random_forest,
    'xgboost': xgboost,
    'svc': svc,
    'knn_classifier': knn_classifier,
    'perceptron_classifier': perceptron_classifier
}

st.title("ML –ê–Ω—Å–∞–º–±–ª—å")

# ======= –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π =======
selected_function_names = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏", list(available_functions.keys()))

# ======= –í–≤–æ–¥ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ =======
func_params = {}
for name in selected_function_names:
    func = available_functions[name]
    sig = inspect.signature(func)
    params_to_remove = {'X_train', 'X_test', 'y_train', 'y_test'}
    new_params = {
        name: param 
        for name, param in sig.parameters.items()
        if name not in params_to_remove
    }
    sig = sig.replace(parameters=list(new_params.values()))
    #sig = list(sig)
    #sig = sig.remove(X_train)
    #sig = sig.remove(X_test)
    #sig = sig.remove(y_train)
    #sig = sig.remove(y_test)
    st.subheader(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è {name}")
    params = {}
    for param in sig.parameters.values():
        default_val = "" if param.default is param.empty else param.default
        input_val = st.text_input(f"{name} - {param.name}", value=str(default_val))
        params[param.name] = eval(input_val)
    params["X_train"] = X_train 
    params["X_test"] = X_test 
    params["y_train"] = y_train 
    params["y_test"] = y_test 
    func_params[name] = params
    

# ======= –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ =======
if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω—Å–∞–º–±–ª—å"):
    merged_df = None
    for name in selected_function_names:
        func = available_functions[name]
        params = func_params.get(name, {})
        result = func(**params)
        if merged_df is None:
            merged_df = result
        else:
            merged_df = pd.merge(merged_df, result, on=['index', 'Style'])

    # ======= –ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ =======
    pred_cols = [col for col in merged_df.columns if col.endswith('_predict')]
    def majority_vote(row):
        votes = [row[col] for col in pred_cols]
        return Counter(votes).most_common(1)[0][0]

    merged_df['overall_predict'] = merged_df.apply(majority_vote, axis=1)

    # ======= Accuracy (–µ—Å–ª–∏ –µ—Å—Ç—å —Å—Ç–æ–ª–±–µ—Ü ground truth) =======
    if 'Style' in merged_df.columns:
        acc = (merged_df['overall_predict'] == merged_df['Style']).mean()
        st.write(f"Accuracy: {acc:.2%}")
    
    st.write("–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω—Å–∞–º–±–ª—è:")
    st.dataframe(merged_df[['Style', 'overall_predict']])
